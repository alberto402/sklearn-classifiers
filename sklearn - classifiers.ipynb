{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from statsmodels.tools.eval_measures import rmse # Para calcular el error\n",
    "\n",
    "from math import sqrt\n",
    "import scipy.cluster.hierarchy as hac\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICADORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos para clasificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lineas Totales-->58165\n",
      "1059\n",
      "Train Mejora >= 30  :  672\n",
      "Train Mejora <  30  :  672\n",
      "Test Mejora >= 30  :  387\n",
      "Test Mejora <  30  :  387\n",
      "Entrenamiento-->1344\n",
      "Test774\n",
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bef_passes_accurate',\n",
       " 'bef_passes_total',\n",
       " 'bef_percent_passes',\n",
       " 'bef_passes_into_opponent_box',\n",
       " 'bef_passes_key',\n",
       " 'bef_open_play_key_passes',\n",
       " 'bef_open_play_passes_into_opponent_box',\n",
       " 'bef_long_passes_successful',\n",
       " 'bef_long_passes_total',\n",
       " 'bef_percent_long_passes',\n",
       " 'bef_crosses_successful',\n",
       " 'bef_crosses_total',\n",
       " 'bef_percent_crosses',\n",
       " 'bef_tackles_successful_with_possession',\n",
       " 'bef_tackles_successful_without_possession',\n",
       " 'bef_tackles_unsuccessful',\n",
       " 'bef_tackles_total',\n",
       " 'bef_adjusted_tackles',\n",
       " 'bef_tackles_was_dribbled',\n",
       " 'bef_interceptions',\n",
       " 'bef_adjusted_interceptions',\n",
       " 'bef_clearance_total',\n",
       " 'bef_adjusted_clearances',\n",
       " 'bef_fouls_committed',\n",
       " 'bef_aerials_won',\n",
       " 'bef_aerials_total',\n",
       " 'bef_percent_aerials',\n",
       " 'bef_assists',\n",
       " 'bef_dribbles_won',\n",
       " 'bef_dispossessed',\n",
       " 'bef_recoveries',\n",
       " 'bef_adjusted_recoveries',\n",
       " 'bef_chances_created',\n",
       " 'bef_through_balls',\n",
       " 'bef_through_balls_accurate',\n",
       " 'bef_scoring_contribution',\n",
       " 'bef_touches',\n",
       " 'bef_touches_in_opponent_box',\n",
       " 'bef_shots_on_target',\n",
       " 'bef_saved_shots_no_gk',\n",
       " 'bef_shots_blocked_by_gk',\n",
       " 'bef_goals',\n",
       " 'bef_goals_penalty',\n",
       " 'bef_non_penalty_goals',\n",
       " 'bef_goals_open_play',\n",
       " 'bef_goals_set_play',\n",
       " 'bef_shots_total',\n",
       " 'bef_shooting',\n",
       " 'bef_goal_conversion',\n",
       " 'bef_saves_total',\n",
       " 'bef_blocked_crosses',\n",
       " 'bef_penalties_faced',\n",
       " 'bef_penalties_scored',\n",
       " 'bef_penalties_missed',\n",
       " 'bef_penalties_save',\n",
       " 'bef_penalty_shots_received_on_target',\n",
       " 'bef_dribbles_total',\n",
       " 'bef_percent_dribbles',\n",
       " 'bef_headers_goal',\n",
       " 'bef_headers_on_target',\n",
       " 'bef_headers_total',\n",
       " 'bef_age',\n",
       " 'bef_TIER',\n",
       " 'bef_Score',\n",
       " 'inc_tier',\n",
       " 'games',\n",
       " 'xg',\n",
       " 'xa',\n",
       " 'xa_open_play',\n",
       " 'xa_set_piece',\n",
       " 'xg_chain',\n",
       " 'xg_build_up',\n",
       " 'individual_pressure',\n",
       " 'ball_progression',\n",
       " 'xg_chain_in_team',\n",
       " 'xg_header']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejora = 30\n",
    "edad_min=20\n",
    "edad_max=40\n",
    "\n",
    "#cargamos fichero\n",
    "datos = pd.read_csv('rawTodos.csv', na_values='na')\n",
    "print(\"lineas Totales-->\"+str(len(datos)))\n",
    "datos=datos.drop(['bef_percent_saves','bef_secondary_position'], axis=1)\n",
    "#Filtrado por minutos\n",
    "datos=datos[datos.bef_mins_played>=400]\n",
    "#Fitramos Score no supere 10\n",
    "\n",
    "\n",
    "#Filtrado edades\n",
    "datos=datos[datos.bef_age <= edad_max]\n",
    "datos=datos[datos.bef_age >= edad_min]\n",
    "\n",
    "#Si queremos filtrar por posicion TODAS LAS POSICIONES --> 'GK','DC','DL','DR','DMC','DML','DMR','MC','ML','MR','AMC','AMR','AML','FW','FWL','FWR'\n",
    "array = ['DC']\n",
    "#array = ['GK']\n",
    "\n",
    "datos=datos.loc[datos.bef_position.isin(array)] \n",
    "\n",
    "datos=datos[datos.bef_Score <= 10]\n",
    "datos=datos[datos.aft_Score <= 10]\n",
    "datos=datos[datos.bef_Score >= 1]\n",
    "datos=datos[datos.aft_Score >= 1]\n",
    "datos= datos.rename(columns={'inc_score': 'label'})\n",
    "cont=0\n",
    "for a in datos['label']:\n",
    "    if(a>30): cont+=1\n",
    "print(f'{cont}')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#PARA PORTEROS\n",
    "datos=datos[['label', 'bef_age','bef_TIER', 'bef_Score','xg_faced', 'xg_faced_on_target', 'xg_saved','bef_passes_total_own_half_accurate',\n",
    "             'bef_passes_total_own_half', 'bef_passes_total_opp_half_accurate', 'bef_passes_total_opp_half',\n",
    "             'bef_passes_total_final_third_accurate', 'bef_passes_total_final_third','bef_saves_in_box',\n",
    "             'bef_saves_out_of_box', 'bef_goals_received', 'bef_goals_received_in_box', 'bef_goals_received_out_box',\n",
    "             'bef_non_penalty_goals_received', 'bef_saved_shots_faced_total', 'bef_saved_shots_faced_in_box',\n",
    "             'bef_saved_shots_faced_out_box', 'bef_shots_received_on_target_total', \n",
    "             'bef_shots_received_on_target_in_box', 'bef_shots_received_on_target_out_box',\n",
    "             'bef_non_penalty_shots_received_on_target', 'bef_missed_shots_faced_total', 'bef_missed_shots_faced_in_box', \n",
    "             'bef_missed_shots_faced_out_box', 'bef_shots_on_post_faced_total', 'bef_shots_on_post_faced_in_box',\n",
    "             'bef_shots_on_post_faced_out_box', 'bef_shots_received_off_target_total', 'bef_shots_received_off_target_in_box',\n",
    "             'bef_shots_received_off_target_out_box', 'bef_shots_received_total', 'bef_shots_received_in_box',\n",
    "             'bef_shots_received_out_box', 'bef_non_penalty_shots_received','bef_yellow_cards','bef_second_yellow_cards',\n",
    "                                       'bef_red_cards']]\n",
    "\"\"\"\n",
    "#filtramos el incremento en mejora o no mejora\n",
    "datos.loc[datos.label <mejora, 'label'] = 0\n",
    "datos.loc[datos.label >=mejora, 'label'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# entrenamiento y test\n",
    "train_features, test_features = train_test_split(datos, test_size=0.35)\n",
    "\n",
    "train_labels = train_features['label']\n",
    "test_labels = test_features['label']\n",
    "#BALANCEO\n",
    "\n",
    "idxs_pos = pd.DataFrame(train_labels)[train_labels==1].index\n",
    "idxs_neg = pd.DataFrame(pd.DataFrame(train_labels)[train_labels==0]).sample(n=len(idxs_pos), replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg)) #numero de filas excogidas(la 4,19, ....)\n",
    "train_labels= pd.DataFrame(train_labels).loc[idxs_balanced].values\n",
    "train_features= pd.DataFrame(train_features).loc[idxs_balanced]\n",
    "print(\"Train Mejora >=\",mejora,\" : \",str(len(idxs_pos)))\n",
    "print(\"Train Mejora < \",mejora,\" : \",str(len(idxs_neg)))\n",
    "\n",
    "\n",
    "a = pd.DataFrame(test_labels)[test_labels==1].index.values\n",
    "b = pd.DataFrame(pd.DataFrame(test_labels)[test_labels==0]).sample(n=len(a), replace=False, random_state=0).index\n",
    "c = np.concatenate((a,b)) #numero de filas excogidas(la 4,19, ....)\n",
    "test_labels= pd.DataFrame(test_labels).loc[c].values\n",
    "test_features= pd.DataFrame(test_features).loc[c]\n",
    "print(\"Test Mejora >=\",mejora,\" : \",str(len(a)))\n",
    "print(\"Test Mejora < \",mejora,\" : \",str(len(b)))\n",
    "\n",
    "test_features_copia=test_features\n",
    "train_features_copia=train_features\n",
    "#BORRADO DE COLUMMNAS IMNECESARIAS\n",
    "#PARA JUGADORES DE CAMPO\n",
    "train_features = train_features.drop([#'aft_Score2',\n",
    "                    'aft_TIER',\n",
    "                    'mins_played','bef_mins_played',\n",
    "                                      'bef_player_id','bef_team_id','bef_season_id',\n",
    "                                      'bef_first_name','bef_Team','bef_year',\n",
    "                                      'bef_name','bef_league_id',\n",
    "                                      'bef_passes_accurate_in_team','bef_source','bef_touches_in_team',\n",
    "                                      'bef_loaded_at','bef_percent_passes_own_half','bef_percent_passes_opp_half',\n",
    "                                      'bef_percent_passes_final_third',\n",
    "                                      'bef_Score2','bef_lined_up', 'bef_subbed_in', 'bef_subbed_out',\n",
    "                                      'bef_games_played','aft_Score',\n",
    "                                      'bef_position','bef_league_id','bef_possession', 'bef_calculated_possession',\n",
    "                                        'xg_faced', 'xg_faced_on_target', 'xg_saved',\n",
    "                                      'bef_passes_total_own_half_accurate', 'bef_passes_total_own_half', \n",
    "                                      'bef_passes_total_opp_half_accurate', 'bef_passes_total_opp_half', \n",
    "                                      'bef_passes_total_final_third_accurate', 'bef_passes_total_final_third',\n",
    "                                      'bef_saves_in_box', 'bef_saves_out_of_box', 'bef_goals_received', \n",
    "                                      'bef_goals_received_in_box', 'bef_goals_received_out_box', \n",
    "                                      'bef_non_penalty_goals_received', 'bef_saved_shots_faced_total',\n",
    "                                      'bef_saved_shots_faced_in_box', 'bef_saved_shots_faced_out_box',\n",
    "                                      'bef_shots_received_on_target_total', 'bef_shots_received_on_target_in_box',\n",
    "                                      'bef_shots_received_on_target_out_box', 'bef_non_penalty_shots_received_on_target',\n",
    "                                      'bef_missed_shots_faced_total', 'bef_missed_shots_faced_in_box',\n",
    "                                      'bef_missed_shots_faced_out_box', 'bef_shots_on_post_faced_total', \n",
    "                                      'bef_shots_on_post_faced_in_box', 'bef_shots_on_post_faced_out_box',\n",
    "                                      'bef_shots_received_off_target_total', 'bef_shots_received_off_target_in_box',\n",
    "                                      'bef_shots_received_off_target_out_box', 'bef_shots_received_total',\n",
    "                                      'bef_shots_received_in_box', 'bef_shots_received_out_box',\n",
    "                                      'bef_non_penalty_shots_received','bef_events_zone_p1','bef_events_zone_p2',\n",
    "                                      'bef_events_zone_p3', 'bef_events_zone_p4','bef_events_zone_p5', 'bef_events_zone_p6',\n",
    "                                      'bef_events_zone_p7', 'bef_events_zone_p8',\n",
    "                                      'bef_events_zone_p9', 'bef_events_30_zone_p1',\n",
    "                                       'bef_events_30_zone_p2', 'bef_events_30_zone_p3',\n",
    "                                      'bef_events_30_zone_p4', 'bef_events_30_zone_p5',\n",
    "                                     'bef_events_30_zone_p6', 'bef_events_30_zone_p7',\n",
    "                                     'bef_events_30_zone_p8', 'bef_events_30_zone_p9',\n",
    "                                     'bef_events_30_zone_p10', 'bef_events_30_zone_p11',\n",
    "                                     'bef_events_30_zone_p12', 'bef_events_30_zone_p13',\n",
    "                                     'bef_events_30_zone_p14', 'bef_events_30_zone_p15',\n",
    "                                     'bef_events_30_zone_p16', 'bef_events_30_zone_p17',\n",
    "                                     'bef_events_30_zone_p18', 'bef_events_30_zone_p19',\n",
    "                                     'bef_events_30_zone_p20', 'bef_events_30_zone_p21',\n",
    "                                     'bef_events_30_zone_p22', 'bef_events_30_zone_p23',\n",
    "                                     'bef_events_30_zone_p24', 'bef_events_30_zone_p25',\n",
    "                                     'bef_events_30_zone_p26', 'bef_events_30_zone_p27',\n",
    "                                     'bef_events_30_zone_p28', 'bef_events_30_zone_p29',\n",
    "                                     'bef_events_30_zone_p30','bef_yellow_cards','bef_second_yellow_cards',\n",
    "                                       'bef_red_cards'], axis=1)\n",
    "test_features = test_features.drop([#'aft_Score2',\n",
    "                    'aft_TIER',\n",
    "                    'mins_played','bef_mins_played',\n",
    "                                      'bef_player_id','bef_team_id','bef_season_id',\n",
    "                                      'bef_first_name','bef_Team','bef_year',\n",
    "                                      'bef_name','bef_league_id',\n",
    "                                      'bef_passes_accurate_in_team','bef_source','bef_touches_in_team',\n",
    "                                      'bef_loaded_at','bef_percent_passes_own_half','bef_percent_passes_opp_half',\n",
    "                                      'bef_percent_passes_final_third',\n",
    "                                      'bef_Score2','bef_lined_up', 'bef_subbed_in', 'bef_subbed_out',\n",
    "                                      'bef_games_played','aft_Score',\n",
    "                                      'bef_position','bef_league_id','bef_possession', 'bef_calculated_possession',\n",
    "                                        'xg_faced', 'xg_faced_on_target', 'xg_saved',\n",
    "                                      'bef_passes_total_own_half_accurate', 'bef_passes_total_own_half', \n",
    "                                      'bef_passes_total_opp_half_accurate', 'bef_passes_total_opp_half', \n",
    "                                      'bef_passes_total_final_third_accurate', 'bef_passes_total_final_third',\n",
    "                                      'bef_saves_in_box', 'bef_saves_out_of_box', 'bef_goals_received', \n",
    "                                      'bef_goals_received_in_box', 'bef_goals_received_out_box', \n",
    "                                      'bef_non_penalty_goals_received', 'bef_saved_shots_faced_total',\n",
    "                                      'bef_saved_shots_faced_in_box', 'bef_saved_shots_faced_out_box',\n",
    "                                      'bef_shots_received_on_target_total', 'bef_shots_received_on_target_in_box',\n",
    "                                      'bef_shots_received_on_target_out_box', 'bef_non_penalty_shots_received_on_target',\n",
    "                                      'bef_missed_shots_faced_total', 'bef_missed_shots_faced_in_box',\n",
    "                                      'bef_missed_shots_faced_out_box', 'bef_shots_on_post_faced_total', \n",
    "                                      'bef_shots_on_post_faced_in_box', 'bef_shots_on_post_faced_out_box',\n",
    "                                      'bef_shots_received_off_target_total', 'bef_shots_received_off_target_in_box',\n",
    "                                      'bef_shots_received_off_target_out_box', 'bef_shots_received_total',\n",
    "                                      'bef_shots_received_in_box', 'bef_shots_received_out_box',\n",
    "                                      'bef_non_penalty_shots_received','bef_events_zone_p1','bef_events_zone_p2',\n",
    "                                      'bef_events_zone_p3', 'bef_events_zone_p4','bef_events_zone_p5', 'bef_events_zone_p6',\n",
    "                                      'bef_events_zone_p7', 'bef_events_zone_p8',\n",
    "                                      'bef_events_zone_p9', 'bef_events_30_zone_p1',\n",
    "                                       'bef_events_30_zone_p2', 'bef_events_30_zone_p3',\n",
    "                                      'bef_events_30_zone_p4', 'bef_events_30_zone_p5',\n",
    "                                     'bef_events_30_zone_p6', 'bef_events_30_zone_p7',\n",
    "                                     'bef_events_30_zone_p8', 'bef_events_30_zone_p9',\n",
    "                                     'bef_events_30_zone_p10', 'bef_events_30_zone_p11',\n",
    "                                     'bef_events_30_zone_p12', 'bef_events_30_zone_p13',\n",
    "                                     'bef_events_30_zone_p14', 'bef_events_30_zone_p15',\n",
    "                                     'bef_events_30_zone_p16', 'bef_events_30_zone_p17',\n",
    "                                     'bef_events_30_zone_p18', 'bef_events_30_zone_p19',\n",
    "                                     'bef_events_30_zone_p20', 'bef_events_30_zone_p21',\n",
    "                                     'bef_events_30_zone_p22', 'bef_events_30_zone_p23',\n",
    "                                     'bef_events_30_zone_p24', 'bef_events_30_zone_p25',\n",
    "                                     'bef_events_30_zone_p26', 'bef_events_30_zone_p27',\n",
    "                                     'bef_events_30_zone_p28', 'bef_events_30_zone_p29',\n",
    "                                     'bef_events_30_zone_p30','bef_yellow_cards','bef_second_yellow_cards',\n",
    "                                       'bef_red_cards'], axis=1)\n",
    "\n",
    "#train_features = train_features.drop(['label','aft_Score','bef_mins_played'], axis=1).values\n",
    "#test_features = test_features.drop(['label','aft_Score','bef_mins_played'], axis=1).values\n",
    "\n",
    "train_features =train_features.drop('label', axis=1)\n",
    "test_features =test_features.drop('label', axis=1)\n",
    "columnas = list(train_features)\n",
    "\n",
    "#datos['label']\n",
    "print(\"Entrenamiento-->\"+str(len(train_features)))\n",
    "print(\"Test\"+str(len(test_features)))\n",
    "print(str(len(columnas)))\n",
    "\n",
    "columnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7264631043256997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71       393\n",
      "         1.0       0.71      0.77      0.74       393\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       786\n",
      "   macro avg       0.73      0.73      0.73       786\n",
      "weighted avg       0.73      0.73      0.73       786\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267</td>\n",
       "      <td>126</td>\n",
       "      <td>89</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  267  126  89  304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss='deviance', random_state=0)\n",
    "gbc.fit(train_features, train_labels)\n",
    "prediccion = gbc.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "rms = sqrt(mean_squared_error(test_labels, prediccion))\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting con validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=3)]: Done   7 out of  10 | elapsed:    5.8s remaining:    2.4s\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (1,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-cb54d0164dcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediccion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,4)"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting con validacion cruzada\n",
    "params = [{'loss': ['deviance', 'exponential']}]\n",
    "gbcc = GridSearchCV(gbc, params, cv=5, scoring='recall', verbose=10, n_jobs=3)\n",
    "gbcc.fit(train_features, train_labels)\n",
    "gbc = gbcc\n",
    "prediccion = gbc.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "rms = sqrt(mean_squared_error(test_labels, prediccion))\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7622739018087855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77       387\n",
      "         1.0       0.78      0.74      0.76       387\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       774\n",
      "   macro avg       0.76      0.76      0.76       774\n",
      "weighted avg       0.76      0.76      0.76       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn  fp   fn   tp\n",
       "0  304  83  101  286"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "modelo = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.5, fit_intercept=True, intercept_scaling=1, class_weight='balanced', random_state=None, \n",
    "                            solver='lbfgs', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=3)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "proba =  modelo.predict_proba(test_features)\n",
    "#Jugadores de interes\n",
    "idx = pd.DataFrame(proba)[proba[:,1]>0.9].index\n",
    "#for a in idx:\n",
    "   # print(test_features_copia[test_features_copia.index==a])\n",
    "cota  = 0.56 # si el 1 está por debajo de esto, considerarlo un cero\n",
    "\n",
    "prediccion = np.round(prediccion)\n",
    "prediccion= pd.DataFrame(prediccion)\n",
    "\n",
    "cambiame = pd.DataFrame(proba)[proba[:,1]<cota].index\n",
    "for i in cambiame:\n",
    "    prediccion[prediccion.index==i]=0\n",
    "    \n",
    "report = classification_report(test_labels, prediccion.values)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7364341085271318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.73       387\n",
      "         1.0       0.72      0.77      0.75       387\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       774\n",
      "   macro avg       0.74      0.74      0.74       774\n",
      "weighted avg       0.74      0.74      0.74       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>116</td>\n",
       "      <td>88</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  271  116  88  299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "modelo = RandomForestRegressor(n_estimators=350, oob_score = True, random_state=0, n_jobs=3)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "prediccion = np.round(prediccion)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RamdomForest clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.6908396946564885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.74      0.70       393\n",
      "         1.0       0.71      0.65      0.68       393\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       786\n",
      "   macro avg       0.69      0.69      0.69       786\n",
      "weighted avg       0.69      0.69      0.69       786\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>104</td>\n",
       "      <td>139</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp   fn   tp\n",
       "0  289  104  139  254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RamdomForest clasificador\n",
    "modelo = RandomForestClassifier(criterion='gini', random_state=0)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=3)]: Done  50 out of  50 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7493540051679587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.62      0.71       387\n",
      "         1.0       0.70      0.88      0.78       387\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       774\n",
      "   macro avg       0.77      0.75      0.74       774\n",
      "weighted avg       0.77      0.75      0.74       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>148</td>\n",
       "      <td>46</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  239  148  46  341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = [{'kernel': ['rbf'], 'gamma': [0.01], 'C': [0.001, 0.01, 0.1, 1, 10]}, \n",
    "              {'kernel': ['linear'], 'gamma': [0.01],  'C':  [0.001, 0.01, 0.1, 1, 10]}\n",
    "             ]\n",
    "#Executa grid search com cross validation\n",
    "modelo = GridSearchCV(svm.SVC(C=1), params, cv=5, scoring='recall', verbose=10, n_jobs=3)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI SE QUIERE BALANCEO EJECUTAR SIGUIENTE LINEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "698\n",
      "361\n",
      "361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idxs_pos = pd.DataFrame(train_labels)[train_labels==1].index\n",
    "idxs_neg = pd.DataFrame(pd.DataFrame(train_labels)[train_labels==0]).sample(n=len(idxs_pos), replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg)) #numero de filas excogidas(la 4,19, ....)\n",
    "train_labels= pd.DataFrame(train_labels).loc[idxs_balanced].values\n",
    "train_features= pd.DataFrame(train_features).loc[idxs_balanced]\n",
    "\n",
    "print(str(len(idxs_pos)))\n",
    "print(str(len(idxs_neg)))\n",
    "\n",
    "a = pd.DataFrame(test_labels)[test_labels==1].index.values\n",
    "b = pd.DataFrame(pd.DataFrame(test_labels)[test_labels==0]).sample(n=len(a), replace=False, random_state=0).index\n",
    "c = np.concatenate((a,b)) #numero de filas excogidas(la 4,19, ....)\n",
    "test_labels= pd.DataFrame(test_labels).loc[c].values\n",
    "test_features= pd.DataFrame(test_features).loc[c]\n",
    "\n",
    "print(str(len(a)))\n",
    "print(str(len(b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7635658914728682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.72      0.75       387\n",
      "         1.0       0.74      0.81      0.77       387\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       774\n",
      "   macro avg       0.77      0.76      0.76       774\n",
      "weighted avg       0.77      0.76      0.76       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>108</td>\n",
       "      <td>75</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  279  108  75  312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "modelo = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.6653944020356234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.53      0.61       393\n",
      "         1.0       0.63      0.80      0.70       393\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       786\n",
      "   macro avg       0.68      0.67      0.66       786\n",
      "weighted avg       0.68      0.67      0.66       786\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  209  184  79  314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "modelo= GaussianNB()\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.5572519083969466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.66      0.60       393\n",
      "         1.0       0.57      0.45      0.50       393\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       786\n",
      "   macro avg       0.56      0.56      0.55       786\n",
      "weighted avg       0.56      0.56      0.55       786\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261</td>\n",
       "      <td>132</td>\n",
       "      <td>216</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp   fn   tp\n",
       "0  261  132  216  177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "modelo = BernoulliNB()\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.6498708010335917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.64      0.65       387\n",
      "         1.0       0.65      0.66      0.65       387\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       774\n",
      "   macro avg       0.65      0.65      0.65       774\n",
      "weighted avg       0.65      0.65      0.65       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248</td>\n",
       "      <td>139</td>\n",
       "      <td>132</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp   fn   tp\n",
       "0  248  139  132  255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-129fc999f5e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m dot_data = tree.export_graphviz(modelo,\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "modelo = tree.DecisionTreeClassifier(random_state=0)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import collections\n",
    "dot_data = tree.export_graphviz(modelo,\n",
    "                                feature_names=columnas,\n",
    "                                out_file=None,\n",
    "                                filled=True,\n",
    "                                rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "colors = ('turquoise', 'orange')\n",
    "edges = collections.defaultdict(list)\n",
    "\n",
    "for edge in graph.get_edge_list():\n",
    "    edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "for edge in edges:\n",
    "    edges[edge].sort()    \n",
    "    for i in range(2):\n",
    "        dest = graph.get_node(str(edges[edge][i]))[0]\n",
    "        dest.set_fillcolor(colors[i])\n",
    "\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.6628498727735369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.66      0.66       393\n",
      "         1.0       0.66      0.66      0.66       393\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       786\n",
      "   macro avg       0.66      0.66      0.66       786\n",
      "weighted avg       0.66      0.66      0.66       786\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp   fn   tp\n",
       "0  260  133  132  261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "modelo = AdaBoostClassifier(tree.DecisionTreeClassifier(),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=500)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7416020671834626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.71      0.73       387\n",
      "         1.0       0.73      0.77      0.75       387\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       774\n",
      "   macro avg       0.74      0.74      0.74       774\n",
      "weighted avg       0.74      0.74      0.74       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "      <td>111</td>\n",
       "      <td>89</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  276  111  89  298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "modelo=BaggingClassifier(  n_estimators = 250 , max_samples = 1.0 ,\n",
    "                           bootstrap = True , bootstrap_features = False ,\n",
    "                         oob_score = False , warm_start = False , n_jobs = None , random_state = 0 , verbose = 0 )\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7338501291989664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.72       387\n",
      "         1.0       0.72      0.77      0.74       387\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       774\n",
      "   macro avg       0.74      0.73      0.73       774\n",
      "weighted avg       0.74      0.73      0.73       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269</td>\n",
       "      <td>118</td>\n",
       "      <td>88</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  269  118  88  299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "modelo = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7558139534883721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.72      0.75       387\n",
      "         1.0       0.74      0.79      0.76       387\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       774\n",
      "   macro avg       0.76      0.76      0.76       774\n",
      "weighted avg       0.76      0.76      0.76       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>109</td>\n",
       "      <td>80</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn   fp  fn   tp\n",
       "0  278  109  80  307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelo=MLPClassifier(alpha=1)\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification rate: 0.7583979328165374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.76      0.76       387\n",
      "         1.0       0.76      0.75      0.76       387\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       774\n",
      "   macro avg       0.76      0.76      0.76       774\n",
      "weighted avg       0.76      0.76      0.76       774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tn  fp  fn   tp\n",
       "0  295  92  95  292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "modelo== linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\n",
    "modelo.fit(train_features, train_labels)\n",
    "prediccion = modelo.predict(test_features)\n",
    "report = classification_report(test_labels, prediccion)\n",
    "print(\"Correct classification rate:\", accuracy_score(test_labels, prediccion))\n",
    "print(report)\n",
    "cm = confusion_matrix(test_labels, prediccion).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "selectKBest = SelectKBest(chi2, 84)\n",
    "selectKBest.fit(train_features, train_labels)\n",
    "best_train_features = selectKBest.transform(train_features)\n",
    "\n",
    "\n",
    "idxs_selected = selectKBest.get_support(indices=True)\n",
    "#Ahora tan solo de toda las caracteristicas que tenemos selecionamos los indices especificos\n",
    "\n",
    "best_train_features = pd.DataFrame(train_features).iloc[:,idxs_selected]\n",
    "#Selected columns.\n",
    "print(best_train_features.columns) # selected columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
